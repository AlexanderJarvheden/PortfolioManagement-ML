{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/robertmartin8/PyPortfolioOpt/blob/master/cookbook/4-Black-Litterman-Allocation.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see install.md to get this working\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "# PyPortfolioOpt\n",
    "from pypfopt import risk_models, expected_returns\n",
    "from pypfopt import black_litterman\n",
    "from pypfopt import BlackLittermanModel, plotting\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "\n",
    "from xgb import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETFs = [\"SPY\", \"BND\", \"GLD\", \"HODL.PA\"]\n",
    "ohlc = yf.download(ETFs, period=\"15y\")  # Open, High, Low, Close\n",
    "closing_prices = ohlc[\"Close\"]\n",
    "closing_prices.tail()\n",
    "\n",
    "# Shows closing prices for the ETFs the last 5 days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get closing prices, and show 5 latest ones. \n",
    "stock_prices = yf.download(\"SPY\", period=\"15y\")[\"Close\"].dropna()\n",
    "stock_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_prices = yf.download(\"GLD\", period=\"15y\")[\"Close\"].dropna()\n",
    "gold_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_prices = yf.download(\"BND\", period=\"15y\")[\"Close\"].dropna()\n",
    "bond_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_prices = yf.download(\"HODL.PA\", period=\"15y\")[\"Close\"].dropna()\n",
    "crypto_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only fetches market caps for SPY and GLD\n",
    "\n",
    "# mcaps = {}\n",
    "# for t in ETFs:\n",
    "#     try:\n",
    "#         mcaps[t] = yf.Ticker(t).info[\"marketCap\"]\n",
    "#     except KeyError:\n",
    "#         print(f\"Inget market cap för {t}\")\n",
    "# mcaps\n",
    "\n",
    "# Using hardcoded values instead:\n",
    "mcaps = {\n",
    "    \"SPY\": 481_714_784_600,     # manuellt från https://www.nasdaq.com/market-activity/etf/spy\n",
    "    \"BND\": 122_936_437_056,     # manuellt från https://www.nasdaq.com/market-activity/etf/bnd\n",
    "    \"GLD\": 77_500_318_000,      # manuellt från https://www.nasdaq.com/market-activity/etf/gld\n",
    "    \"HODL.PA\": 1_200_295_500   #change to .PA     # manuellt från https://www.nasdaq.com/market-activity/etf/hodl\n",
    "}\n",
    "mcaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix between all assets\n",
    "cov_matrix = risk_models.CovarianceShrinkage(closing_prices).ledoit_wolf()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk aversion\n",
    "delta = black_litterman.market_implied_risk_aversion(stock_prices)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_covariance(cov_matrix, plot_correlation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior implied returns (Pi), N×1 column vector\n",
    "market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, cov_matrix)\n",
    "market_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_prior.plot.barh(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views\n",
    "Q contains the magnitude of each view, while P maps the views to the assets they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Absolute views, this should be coming from XGBoost, placeholder values atm\n",
    "# viewdict = {\n",
    "#     \"SPY\": 0.08,      # t.ex. +8% förväntad avkastning\n",
    "#     \"BND\": 0.03,      \n",
    "#     \"GLD\": 0.01,      \n",
    "#     \"HODL\": 0.20,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View confidence\n",
    "Using Idzorek's method\n",
    " - Maybe we can use some error term to evaluate the confidence levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Placeholder values:\n",
    "# confidences = [0.6, 0.5, 0.3, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using idzorek method (specifying our own confidence levels)\n",
    "# # You can also create omega yourself by creating a diagonal matrix based on the views variances\n",
    "# bl_idzorek = BlackLittermanModel(cov_matrix, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Posterior estimate of returns\n",
    "# ret_bl = bl_idzorek.bl_returns()\n",
    "# ret_bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization how this compares to the prior and our views:\n",
    "# rets_df = pd.DataFrame([market_prior, ret_bl, pd.Series(viewdict)], \n",
    "#              index=[\"Prior\", \"Posterior\", \"Views\"]).T\n",
    "# rets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rets_df.plot.bar(figsize=(12,8))\n",
    "# # \"Notice that the posterior is often between the prior and the views. \n",
    "# # This supports the fact that the BL method is essentially a Bayesian weighted-average of the prior and views,\n",
    "# # where the weight is determined by the confidence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Posterior covariance estimate:\n",
    "# cov_bl = bl_idzorek.bl_cov()\n",
    "# plotting.plot_covariance(cov_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypfopt import EfficientFrontier, objective_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ef = EfficientFrontier(ret_bl, cov_bl)\n",
    "# #ef.add_objective(objective_functions.L2_reg)\n",
    "# ef.max_sharpe() # to maximize sharpe ratio, can be changed\n",
    "# weights = ef.clean_weights()\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(weights).plot.pie(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of how much to spend in each asset based on capital\n",
    "# from pypfopt import DiscreteAllocation\n",
    "\n",
    "# da = DiscreteAllocation(weights, closing_prices.iloc[-1], total_portfolio_value=10000)\n",
    "# # alloc, leftover = da.lp_portfolio() funkar ej\n",
    "# alloc, leftover = da.greedy_portfolio()\n",
    "# print(f\"Leftover: ${leftover:.2f}\")\n",
    "# alloc #antal andelar\n",
    "df_crypto = pd.read_csv(\"merged2.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgb import Trainer\n",
    "\n",
    "SCALE   = 1.0          # =1 om du vill använda size oförändrat\n",
    "trainer = Trainer.load(\"models\")     # joblib-filen du sparade\n",
    "\n",
    "viewdict, confidences = {}, []\n",
    "\n",
    "for ticker in ETFs:                         # [\"SPY\", \"BND\", \"GLD\", \"HODL\"]\n",
    "    if ticker == \"HODL.PA\":\n",
    "        # ── läs merged2.csv, sortera, ta sista 8 rader ──────────────\n",
    "        df_crypto = (\n",
    "            pd.read_csv(\"merged2.csv\", parse_dates=[\"Date\"])\n",
    "              .sort_values(\"Date\")\n",
    "              .tail(8)\n",
    "        )\n",
    "        action, size, confidence = trainer.predict(df_crypto)\n",
    "        viewdict[ticker]  = size * SCALE\n",
    "        confidences.append(confidence)\n",
    "    else:\n",
    "        viewdict[ticker]  = 0.0        # neutral vy\n",
    "        confidences.append(0.0)        # låg vikt\n",
    "\n",
    "viewdict, confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Black‑Litterman with Idzorek confidences\n",
    "bl_idzorek = BlackLittermanModel(\n",
    "    cov_matrix,\n",
    "    pi=market_prior,\n",
    "    absolute_views=viewdict,\n",
    "    omega=\"idzorek\",\n",
    "    view_confidences=confidences,\n",
    ")\n",
    "\n",
    "ret_bl = bl_idzorek.bl_returns()\n",
    "cov_bl = bl_idzorek.bl_cov()\n",
    "\n",
    "# Efficient frontier\n",
    "ef = EfficientFrontier(ret_bl, cov_bl)\n",
    "ef.max_sharpe()\n",
    "weights = ef.clean_weights()\n",
    "weights\n",
    "\n",
    "#OrderedDict([('BND', 0.1263),\n",
    "             #('GLD', 0.07962),\n",
    "            # ('HODL', 0.29918),\n",
    "            # ('SPY', 0.49489)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.Series(weights).plot.pie(figsize=(8,8), autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Financial_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "#  BLACK-LITTERMAN: bygg views från färdiga matriser (weekly)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from pypfopt import risk_models, black_litterman, BlackLittermanModel, EfficientFrontier\n",
    "\n",
    "\n",
    "# ▸ 0. SÄKERHETSKOLL  --------------------------------------------------\n",
    "\n",
    "\n",
    "missing = [name for name in needed if name not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Variabler saknas i minnet: {missing}. \"\n",
    "        \"Kör först financial_data.ipynb så att de skapas.\"\n",
    "    )\n",
    "\n",
    "# ▸ 1. SKAPA closing_prices-matris från dina DataFrames  --------------\n",
    "def to_series(df, name):\n",
    "    s = df.set_index(\"Date\")[\"Close\"]\n",
    "    s.index = pd.to_datetime(s.index)\n",
    "    return s.rename(name)\n",
    "\n",
    "closing_prices = pd.concat(\n",
    "    [\n",
    "        to_series(df_bnd,  \"BND\"),\n",
    "        to_series(df_gld,  \"GLD\"),\n",
    "        to_series(df_hodl, \"HODL.PA\"),\n",
    "        to_series(df_spy,  \"SPY\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").sort_index()\n",
    "closing_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ▸ 2. WEEKLY views + confidences  ------------------------------------\n",
    "def weekly_views(sent_df, price_df):\n",
    "    sent_w = sent_df.assign(Date=pd.to_datetime(sent_df[\"Date\"]))\\\n",
    "                    .set_index(\"Date\")\\\n",
    "                    .resample(\"W-FRI\").last().dropna()\n",
    "    px_w   = price_df.resample(\"W-FRI\").last()\n",
    "\n",
    "    colmap = {\"SPY_FGI\":\"SPY\", \"BND_FGI\":\"BND\",\n",
    "              \"GLD_FGI\":\"GLD\", \"Crypto_FGI\":\"HODL.PA\"}\n",
    "    views, conf = {}, []\n",
    "    for scol, tic in colmap.items():\n",
    "        fgi  = sent_w[scol]\n",
    "        prc  = px_w[tic].loc[fgi.index]\n",
    "        fwd  = np.log(prc.shift(-1)/prc)          # 1-veckas log-retur\n",
    "        tmp  = pd.concat({\"cls\":fgi,\"fwd\":fwd}, axis=1).dropna()\n",
    "        cls  = int(fgi.iloc[-1])                  # senaste klass\n",
    "        views[tic] = tmp.groupby(\"cls\")[\"fwd\"].mean().get(cls, 0.0)\n",
    "        conf.append(1 / (tmp.query(\"cls==@cls\")[\"fwd\"].var() + 1e-8))\n",
    "    conf = (np.array(conf)/np.max(conf)).tolist()\n",
    "    return views, conf\n",
    "\n",
    "viewdict, confidences = weekly_views(merged.copy(), closing_prices)\n",
    "print(\"Views:\", viewdict)\n",
    "print(\"Conf :\", confidences)\n",
    "\n",
    "# ▸ 3. BLACK-LITTERMAN  ------------------------------------------------\n",
    "mcaps = {\n",
    "    \"SPY\": 481_714_784_600,\n",
    "    \"BND\": 122_936_437_056,\n",
    "    \"GLD\":  77_500_318_000,\n",
    "    \"HODL.PA\": 1_200_295_500,\n",
    "}\n",
    "cov   = risk_models.CovarianceShrinkage(closing_prices).ledoit_wolf()\n",
    "delta = black_litterman.market_implied_risk_aversion(closing_prices[\"SPY\"])\n",
    "pi    = black_litterman.market_implied_prior_returns(mcaps, delta, cov)\n",
    "\n",
    "bl = BlackLittermanModel(\n",
    "    cov,\n",
    "    pi=pi,\n",
    "    absolute_views=viewdict,\n",
    "    omega=\"idzorek\",\n",
    "    view_confidences=confidences,\n",
    "    risk_aversion=delta,\n",
    ")\n",
    "ef = EfficientFrontier(bl.bl_returns(), bl.bl_cov())\n",
    "ef.max_sharpe()\n",
    "weights = ef.clean_weights()\n",
    "\n",
    "print(\"\\nOPTIMERAD PORTFÖLJ (weekly BL):\")\n",
    "for k, v in weights.items():\n",
    "    print(f\"  {k:7s}: {v*100:5.1f} %\")\n",
    "\n",
    "# (valfritt) visa fördelningen\n",
    "pd.Series(weights).plot.pie(figsize=(6,6), autopct='%1.1f%%')\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Black-Litterman allocation (veckovis)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
